import telebot
from telebot import types
from g4f.client import Client
import requests
from io import BytesIO
import threading
import logging
import base64
import re
import signal
import sys

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
from config import Config

# ===== ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ =====
logging.basicConfig(
    level=getattr(logging, Config.LOG_LEVEL),
    format="%(asctime)s [%(levelname)s] %(message)s"
)

# ===== Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ¾Ñ‚Ğ° =====
try:
    bot = telebot.TeleBot(Config.BOT_TOKEN)
    client = Client()
    logging.info("âœ… Ğ‘Ğ¾Ñ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
except Exception as e:
    logging.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ¾Ñ‚Ğ°: {e}")
    sys.exit(1)


# ===== Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´ Ğ±Ğ¾Ñ‚Ğ° =====
commands = [
    telebot.types.BotCommand("/start", "ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ñ Ğ±Ğ¾Ñ‚Ğ¾Ğ¼"),
    telebot.types.BotCommand("/help", "ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ñ‚Ğ°"),
    telebot.types.BotCommand("/model", "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ Ğ˜Ğ˜"),
    telebot.types.BotCommand("/image_model", "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹"),
    telebot.types.BotCommand("/image_settings", "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹"),
    telebot.types.BotCommand("/image", "Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ"),
    telebot.types.BotCommand("/image_raw", "Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±ĞµĞ· Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°"),
    telebot.types.BotCommand("/analyze", "ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ"),
    telebot.types.BotCommand("/stats", "ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ")
]
bot.set_my_commands(commands)

# ===== ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ =====
user_models = {}
user_image_models = {}
user_image_settings = {}
user_waiting_for_image = {}

# Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
from collections import defaultdict

user_stats = defaultdict(lambda: {
    'messages': 0,
    'images_generated': 0,
    'images_analyzed': 0
})


def update_stats(user_id, action):
    """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"""
    user_stats[user_id][action] += 1


# ========== Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞ˜Ğ• ĞŸĞ ĞĞœĞŸĞ¢ĞĞ’ ==========

TOPIC_KEYWORDS = {
    "nature": "lush vegetation, realistic textures, depth of field",
    "city": "urban landscape, detailed architecture, bustling atmosphere",
    "portrait": "professional portrait, sharp focus on face, natural skin texture",
    "fantasy": "magical atmosphere, ethereal, otherworldly",
    "sci-fi": "futuristic, high-tech, sleek design",
    "food": "appetizing, vibrant colors, soft lighting, macro shot",
    "animal": "detailed fur/feathers, realistic anatomy, dynamic pose",
    "space": "cosmic, stars, nebula, galaxy, deep space",
    "underwater": "underwater scene, coral reef, marine life, light rays",
    "steampunk": "steampunk aesthetic, brass gears, Victorian, industrial",
    "cyberpunk": "cyberpunk, neon lights, rainy, high contrast, futuristic city",
    "anime": "anime style, cel-shaded, vibrant colors, Japanese animation",
    "watercolor": "watercolor painting, soft edges, artistic, textured paper",
    "oil painting": "oil painting, thick brush strokes, impasto, canvas texture",
    "minimalist": "minimalist, simple background, clean lines, less is more"
}

STYLE_KEYWORDS = {
    "anime": "anime style, cel-shaded, vibrant colors, Japanese animation",
    "watercolor": "watercolor painting, soft edges, artistic, textured paper",
    "oil painting": "oil painting, thick brush strokes, impasto, canvas texture",
    "cyberpunk": "cyberpunk aesthetic, neon lights, rainy, high contrast",
    "steampunk": "steampunk style, brass gears, Victorian, industrial",
    "minimalist": "minimalist, simple background, clean lines, less is more",
    "photorealistic": "photorealistic, hyper-realistic, DSLR, 8k, highly detailed",
    "cartoon": "cartoon style, vibrant, exaggerated features",
    "3d render": "3D render, octane render, blender, c4d, detailed textures"
}

LIGHTING_KEYWORDS = {
    "cinematic": "cinematic lighting, volumetric light, moody atmosphere",
    "golden hour": "golden hour, warm sunlight, long shadows, sunset glow",
    "studio": "studio lighting, softbox, well-lit, no harsh shadows",
    "neon": "neon lighting, vibrant glow, dark background, reflective surfaces",
    "dramatic": "dramatic lighting, chiaroscuro, high contrast, spotlight",
    "natural": "natural lighting, soft diffused light, daylight",
    "moody": "moody atmosphere, dim light, shadows, mysterious"
}

COMPOSITION_KEYWORDS = {
    "close-up": "close-up shot, detailed, shallow depth of field, macro",
    "wide": "wide angle, panoramic, expansive view, landscape",
    "aerial": "aerial view, drone shot, bird's eye perspective, top-down",
    "low angle": "low angle shot, dramatic perspective, heroic, upward view",
    "portrait": "portrait composition, rule of thirds, centered subject",
    "symmetrical": "symmetrical composition, balanced, geometric"
}

MODEL_QUALITY_BOOST = {
    "flux": "8k, photorealistic, ultra-detailed, sharp focus, volumetric lighting, HDR",
    "dalle-3": "high quality, detailed, vibrant colors, natural lighting, professional",
    "sdxl": "masterpiece, best quality, highly detailed, intricate details, award-winning",
    "playground-v2.5": "professional, detailed, 8k, artistic, creative composition",
    "midjourney": "award winning, stunning, intricate details, breathtaking --ar 16:9 --style expressive"
}


def detect_topic(prompt):
    prompt_lower = prompt.lower()
    detected = []
    for topic, keywords in TOPIC_KEYWORDS.items():
        if topic in prompt_lower:
            detected.append(keywords)
    return ", ".join(detected) if detected else ""


def detect_style(prompt):
    prompt_lower = prompt.lower()
    detected = []
    for style, keywords in STYLE_KEYWORDS.items():
        if style in prompt_lower:
            detected.append(keywords)
    return ", ".join(detected) if detected else ""


def detect_lighting(prompt):
    prompt_lower = prompt.lower()
    detected = []
    for lighting, keywords in LIGHTING_KEYWORDS.items():
        if lighting in prompt_lower:
            detected.append(keywords)
    return ", ".join(detected) if detected else ""


def detect_composition(prompt):
    prompt_lower = prompt.lower()
    detected = []
    for comp, keywords in COMPOSITION_KEYWORDS.items():
        if comp in prompt_lower:
            detected.append(keywords)
    return ", ".join(detected) if detected else ""


def clean_prompt(prompt):
    """ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ¾Ñ‚ Ğ»Ğ¸ÑˆĞ½Ğ¸Ñ… ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²"""
    prompt = re.sub(r',+', ',', prompt)
    prompt = re.sub(r'\s+,', ',', prompt)
    prompt = re.sub(r',\s+', ', ', prompt)
    prompt = re.sub(r'\.+', '.', prompt)
    return prompt.strip().strip(',').strip()


def improve_prompt(user_prompt, model):
    """Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹"""
    user_prompt = user_prompt.strip().rstrip(',.')

    topics = detect_topic(user_prompt)
    style = detect_style(user_prompt)
    lighting = detect_lighting(user_prompt)
    composition = detect_composition(user_prompt)

    if not lighting:
        lighting = LIGHTING_KEYWORDS.get("cinematic", "cinematic lighting")
    if not composition:
        composition = COMPOSITION_KEYWORDS.get("wide", "professional composition, rule of thirds")

    enhanced_parts = [user_prompt]
    if topics:
        enhanced_parts.append(topics)
    if style:
        enhanced_parts.append(style)
    if lighting:
        enhanced_parts.append(lighting)
    if composition:
        enhanced_parts.append(composition)

    quality_boost = MODEL_QUALITY_BOOST.get(model, "high quality, detailed")
    enhanced_parts.append(quality_boost)

    final_prompt = ", ".join(enhanced_parts)
    final_prompt = clean_prompt(final_prompt)

    return final_prompt


# ===== ĞšĞĞœĞĞĞ”Ğ START =====
@bot.message_handler(commands=['start'])
def start(message):
    bot.send_message(
        message.chat.id,
        f"ğŸ‘‹ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {message.from_user.first_name}!\n\n"
        "ğŸ¤– Ğ¯ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ˜Ğ˜-Ğ±Ğ¾Ñ‚ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹:\n"
        "âœ¨ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° (Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)\n"
        "ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ (5 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²)\n"
        "ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\n\n"
        "ğŸ“– Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ /help Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ° Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´ Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹!"
    )


# ===== Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ =====
@bot.message_handler(commands=['stats'])
def show_stats(message):
    user_id = message.from_user.id
    stats = user_stats.get(user_id, {'messages': 0, 'images_generated': 0, 'images_analyzed': 0})

    bot.send_message(
        message.chat.id,
        f"ğŸ“Š *Ğ’Ğ°ÑˆĞ° ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ*\n\n"
        f"ğŸ’¬ Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {stats['messages']}\n"
        f"ğŸ¨ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: {stats['images_generated']}\n"
        f"ğŸ” Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: {stats['images_analyzed']}\n\n"
        f"ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ğ¹ Ğ² Ñ‚Ğ¾Ğ¼ Ğ¶Ğµ Ğ´ÑƒÑ…Ğµ! ğŸš€",
        parse_mode="Markdown"
    )


# ===== Ğ’Ğ«Ğ‘ĞĞ  Ğ¢Ğ•ĞšĞ¡Ğ¢ĞĞ’ĞĞ™ ĞœĞĞ”Ğ•Ğ›Ğ˜ =====
@bot.message_handler(commands=['model'])
def choose_model(message):
    keyboard = types.InlineKeyboardMarkup()
    current_model = user_models.get(message.from_user.id, Config.DEFAULT_MODEL)

    for name, model_id in Config.AVAILABLE_MODELS.items():
        button_text = f"âœ… {name}" if model_id == current_model else name
        keyboard.add(types.InlineKeyboardButton(
            text=button_text,
            callback_data=f"model:{model_id}"
        ))

    bot.send_message(
        message.chat.id,
        f"ğŸ¤– *Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°*\n\n"
        f"Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: *{current_model}*\n\n"
        f"Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ:",
        reply_markup=keyboard,
        parse_mode="Markdown"
    )


@bot.callback_query_handler(func=lambda call: call.data.startswith("model:"))
def set_model(call):
    model_id = call.data.split(":")[1]
    user_models[call.from_user.id] = model_id

    model_name = next((name for name, mid in Config.AVAILABLE_MODELS.items() if mid == model_id), model_id)

    bot.answer_callback_query(call.id, f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°: {model_name}")
    bot.edit_message_text(
        f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ° Ğ½Ğ°:\n*{model_name}*",
        call.message.chat.id,
        call.message.message_id,
        parse_mode="Markdown"
    )


# ===== Ğ’Ğ«Ğ‘ĞĞ  ĞœĞĞ”Ğ•Ğ›Ğ˜ Ğ”Ğ›Ğ¯ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™ =====
@bot.message_handler(commands=['image_model'])
def choose_image_model(message):
    keyboard = types.InlineKeyboardMarkup()
    current_model = user_image_models.get(message.from_user.id, Config.DEFAULT_IMAGE_MODEL)

    for name, model_id in Config.AVAILABLE_IMAGE_MODELS.items():
        button_text = f"âœ… {name}" if model_id == current_model else name
        keyboard.add(types.InlineKeyboardButton(
            text=button_text,
            callback_data=f"img_model:{model_id}"
        ))

    bot.send_message(
        message.chat.id,
        f"ğŸ¨ *Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹*\n\n"
        f"Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: *{current_model}*\n\n"
        f"Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ:",
        reply_markup=keyboard,
        parse_mode="Markdown"
    )


@bot.callback_query_handler(func=lambda call: call.data.startswith("img_model:"))
def set_image_model(call):
    model_id = call.data.split(":")[1]
    user_image_models[call.from_user.id] = model_id

    model_name = next((name for name, mid in Config.AVAILABLE_IMAGE_MODELS.items() if mid == model_id), model_id)

    bot.answer_callback_query(call.id, f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°: {model_name}")
    bot.edit_message_text(
        f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ° Ğ½Ğ°:\n*{model_name}*",
        call.message.chat.id,
        call.message.message_id,
        parse_mode="Markdown"
    )


# ===== ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™ =====
@bot.message_handler(commands=['image_settings'])
def image_settings_command(message):
    user_id = message.from_user.id
    current_model = user_image_models.get(user_id, Config.DEFAULT_IMAGE_MODEL)
    settings = Config.IMAGE_MODEL_SETTINGS.get(current_model)
    current_size = user_image_settings.get(user_id, {}).get('size', settings['default_size'])

    keyboard = types.InlineKeyboardMarkup()

    sizes = ["1024x1024", "1024x1792", "1792x1024", "512x512"]
    for size in sizes:
        button_text = f"âœ… {size}" if size == current_size else f"ğŸ“ {size}"
        keyboard.add(types.InlineKeyboardButton(
            button_text,
            callback_data=f"set_size:{size}"
        ))

    bot.send_message(
        message.chat.id,
        f"âš™ï¸ *ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹*\n\n"
        f"Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: *{settings['name']}*\n"
        f"Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€: *{current_size}*\n\n"
        f"Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ:",
        reply_markup=keyboard,
        parse_mode="Markdown"
    )


@bot.callback_query_handler(func=lambda call: call.data.startswith("set_size:"))
def set_image_size(call):
    size = call.data.replace("set_size:", "")
    user_id = call.from_user.id

    if user_id not in user_image_settings:
        user_image_settings[user_id] = {}

    user_image_settings[user_id]['size'] = size

    bot.answer_callback_query(call.id, f"Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: {size}")
    bot.edit_message_text(
        f"âœ… Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½ Ğ½Ğ°: *{size}*\n\n"
        f"Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ²ÑĞµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ² ÑÑ‚Ğ¾Ğ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğµ.",
        call.message.chat.id,
        call.message.message_id,
        parse_mode="Markdown"
    )


# ===== Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™ =====
def generate_image_thread(message, raw_mode=False):
    prompt = message.text.replace("/image", "").replace("/image_raw", "").strip()

    if prompt.endswith("--raw"):
        raw_mode = True
        prompt = prompt.replace("--raw", "").strip()

    if not prompt:
        bot.reply_to(
            message,
            "âŒ ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹\n\n"
            "ğŸ“ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: `/image ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ñ‚ Ğ½Ğ° Ğ¼Ğ¾Ñ€Ğµ`\n"
            "ğŸ“ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ±ĞµĞ· ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹: `/image_raw sunset` Ğ¸Ğ»Ğ¸ `/image sunset --raw`",
            parse_mode="Markdown"
        )
        return

    user_id = message.from_user.id
    model = user_image_models.get(user_id, Config.DEFAULT_IMAGE_MODEL)
    settings = Config.IMAGE_MODEL_SETTINGS.get(model, Config.IMAGE_MODEL_SETTINGS["flux"])
    user_size = user_image_settings.get(user_id, {}).get('size', settings.get('default_size', '1024x1024'))

    if raw_mode:
        final_prompt = prompt
        logging.info(f"Raw mode: {final_prompt}")
    else:
        final_prompt = improve_prompt(prompt, model)
        logging.info(f"Original: {prompt} -> Enhanced: {final_prompt}")

    status_msg = bot.send_message(
        message.chat.id,
        f"ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ...\n"
        f"ğŸ“· ĞœĞ¾Ğ´ĞµĞ»ÑŒ: *{settings['name']}*\n"
        f"ğŸ“ Ğ Ğ°Ğ·Ğ¼ĞµÑ€: *{user_size}*",
        parse_mode="Markdown"
    )
    bot.send_chat_action(message.chat.id, "upload_photo")

    try:
        generation_params = {
            "model": model,
            "prompt": final_prompt,
            "response_format": "url"
        }

        if settings.get("supports_size"):
            generation_params["size"] = user_size
        if settings.get("supports_quality"):
            generation_params["quality"] = settings.get("quality", "hd")

        logging.info(f"Generation params: {generation_params}")

        response = client.images.generate(**generation_params)
        image_url = response.data[0].url

        bot.edit_message_text(
            f"ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ...",
            message.chat.id,
            status_msg.message_id
        )

        img_response = requests.get(image_url, timeout=Config.REQUEST_TIMEOUT)
        img_response.raise_for_status()
        image_bytes = BytesIO(img_response.content)
        image_bytes.name = "image.png"

        bot.delete_message(message.chat.id, status_msg.message_id)

        caption = (
            f"ğŸ¨ *ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚:* {prompt}\n"
            f"ğŸ“· *ĞœĞ¾Ğ´ĞµĞ»ÑŒ:* {settings['name']}\n"
            f"ğŸ“ *Ğ Ğ°Ğ·Ğ¼ĞµÑ€:* {generation_params.get('size', 'Ğ°Ğ²Ñ‚Ğ¾')}"
        )
        if not raw_mode:
            caption += "\nâœ¨ *ĞĞ²Ñ‚Ğ¾ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ:* Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾"

        bot.send_photo(message.chat.id, image_bytes, caption=caption, parse_mode="Markdown")

        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
        update_stats(user_id, 'images_generated')

        keyboard = types.InlineKeyboardMarkup()
        keyboard.row(
            types.InlineKeyboardButton("ğŸ”„ Ğ ĞµĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ", callback_data=f"regen:{prompt}:{raw_mode}"),
            types.InlineKeyboardButton("ğŸ¨ Ğ¡Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", callback_data="quick_model_change")
        )
        bot.send_message(message.chat.id, "ğŸ’¡ Ğ§Ñ‚Ğ¾ Ğ´Ğ°Ğ»ÑŒÑˆĞµ?", reply_markup=keyboard)

    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ({model}): {e}")

        fallback_models = ["flux", "dalle-3", "sdxl", "playground-v2.5"]
        fallback_models = [m for m in fallback_models if m != model]

        for fallback in fallback_models:
            try:
                logging.info(f"Trying fallback: {fallback}")
                fallback_settings = Config.IMAGE_MODEL_SETTINGS.get(fallback)

                bot.edit_message_text(
                    f"âš ï¸ ĞŸÑ€Ğ¾Ğ±ÑƒÑ Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {fallback_settings['name']}...",
                    message.chat.id,
                    status_msg.message_id
                )

                fallback_prompt = prompt if raw_mode else improve_prompt(prompt, fallback)
                fallback_params = {
                    "model": fallback,
                    "prompt": fallback_prompt,
                    "response_format": "url"
                }

                if fallback_settings.get("supports_size"):
                    fallback_params["size"] = user_size
                if fallback_settings.get("supports_quality"):
                    fallback_params["quality"] = fallback_settings.get("quality")

                response = client.images.generate(**fallback_params)
                image_url = response.data[0].url

                img_response = requests.get(image_url, timeout=Config.REQUEST_TIMEOUT)
                img_response.raise_for_status()
                image_bytes = BytesIO(img_response.content)
                image_bytes.name = "image.png"

                bot.delete_message(message.chat.id, status_msg.message_id)

                caption = (
                    f"ğŸ¨ *ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚:* {prompt}\n"
                    f"ğŸ“· *ĞœĞ¾Ğ´ĞµĞ»ÑŒ:* {fallback_settings['name']} (Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½Ğ°Ñ)\n"
                    f"ğŸ“ *Ğ Ğ°Ğ·Ğ¼ĞµÑ€:* {fallback_params.get('size', 'Ğ°Ğ²Ñ‚Ğ¾')}"
                )

                bot.send_photo(message.chat.id, image_bytes, caption=caption, parse_mode="Markdown")
                update_stats(user_id, 'images_generated')
                return

            except Exception as fallback_error:
                logging.error(f"Fallback {fallback} failed: {fallback_error}")
                continue

        try:
            bot.edit_message_text(
                "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n\n"
                "Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ:\n"
                "â€¢ Ğ¡Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ‡ĞµÑ€ĞµĞ· /image_model\n"
                "â€¢ ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¶Ğµ\n"
                "â€¢ Ğ£Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ",
                message.chat.id,
                status_msg.message_id
            )
        except:
            bot.send_message(
                message.chat.id,
                "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ."
            )


@bot.message_handler(commands=['image'])
def handle_image(message):
    threading.Thread(target=generate_image_thread, args=(message, False), daemon=True).start()


@bot.message_handler(commands=['image_raw'])
def handle_image_raw(message):
    threading.Thread(target=generate_image_thread, args=(message, True), daemon=True).start()


@bot.callback_query_handler(func=lambda call: call.data.startswith("regen:"))
def regenerate_image(call):
    data = call.data.replace("regen:", "").split(":", 1)
    prompt = data[0]
    raw_mode = data[1].lower() == "true" if len(data) == 2 else False

    bot.answer_callback_query(call.id, "ğŸ”„ Ğ ĞµĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ...")

    class FakeMessage:
        def __init__(self, chat_id, text, user):
            self.chat = type('obj', (object,), {'id': chat_id})
            self.text = f"/image {text}"
            self.from_user = user

    fake_msg = FakeMessage(call.message.chat.id, prompt, call.from_user)
    threading.Thread(target=generate_image_thread, args=(fake_msg, raw_mode), daemon=True).start()


@bot.callback_query_handler(func=lambda call: call.data == "quick_model_change")
def quick_model_change(call):
    bot.answer_callback_query(call.id)
    choose_image_model(call.message)


# ===== ĞĞĞĞ›Ğ˜Ğ— Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™ =====
@bot.message_handler(commands=['analyze'])
def analyze_command(message):
    user_waiting_for_image[message.from_user.id] = {'waiting': True, 'prompt': None}
    bot.send_message(
        message.chat.id,
        "ğŸ“¸ *Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½*\n\n"
        "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ¼Ğ½Ğµ Ñ„Ğ¾Ñ‚Ğ¾ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°.",
        parse_mode="Markdown"
    )


def analyze_image_thread(message, photo, user_prompt=None):
    try:
        status_msg = bot.send_message(message.chat.id, "ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ...")
        bot.send_chat_action(message.chat.id, "typing")

        file_info = bot.get_file(photo.file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        image_base64 = base64.b64encode(downloaded_file).decode('utf-8')

        prompt = user_prompt or "ĞĞ¿Ğ¸ÑˆĞ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ñ‡Ñ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¾ Ğ½Ğ° ÑÑ‚Ğ¾Ğ¼ Ñ„Ğ¾Ñ‚Ğ¾."

        response = client.chat.completions.create(
            model=Config.VISION_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                        }
                    ]
                }
            ],
        )

        analysis = response.choices[0].message.content
        bot.delete_message(message.chat.id, status_msg.message_id)

        max_length = Config.MAX_MESSAGE_LENGTH
        if len(analysis) > max_length:
            for i in range(0, len(analysis), max_length):
                bot.send_message(message.chat.id, analysis[i:i + max_length])
        else:
            bot.send_message(
                message.chat.id,
                f"ğŸ” *ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ:*\n\n{analysis}",
                parse_mode="Markdown"
            )

        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
        update_stats(message.from_user.id, 'images_analyzed')

    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {e}")
        try:
            bot.edit_message_text(
                f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.",
                message.chat.id,
                status_msg.message_id
            )
        except:
            bot.send_message(message.chat.id, "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.")


@bot.message_handler(content_types=['photo'])
def handle_photo(message):
    user_id = message.from_user.id
    photo = message.photo[-1]
    user_prompt = message.caption if message.caption else None

    if user_id in user_waiting_for_image and user_waiting_for_image[user_id]['waiting']:
        user_waiting_for_image[user_id]['waiting'] = False
        threading.Thread(
            target=analyze_image_thread,
            args=(message, photo, user_prompt),
            daemon=True
        ).start()
    else:
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(
            types.InlineKeyboardButton("ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ", callback_data=f"analyze_photo:{photo.file_id}"),
            types.InlineKeyboardButton("âŒ ĞÑ‚Ğ¼ĞµĞ½Ğ°", callback_data="cancel_photo")
        )
        bot.send_message(message.chat.id, "ğŸ“¸ Ğ§Ñ‚Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ñ ÑÑ‚Ğ¸Ğ¼ Ñ„Ğ¾Ñ‚Ğ¾?", reply_markup=keyboard)


@bot.callback_query_handler(func=lambda call: call.data.startswith("analyze_photo:"))
def analyze_photo_callback(call):
    file_id = call.data.split(":")[1]
    bot.answer_callback_query(call.id, "ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ...")

    class PhotoObj:
        def __init__(self, file_id):
            self.file_id = file_id

    photo = PhotoObj(file_id)
    threading.Thread(target=analyze_image_thread, args=(call.message, photo, None), daemon=True).start()
    bot.edit_message_text("ğŸ” ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·...", call.message.chat.id, call.message.message_id)


@bot.callback_query_handler(func=lambda call: call.data == "cancel_photo")
def cancel_photo(call):
    bot.answer_callback_query(call.id, "âŒ ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾")
    bot.delete_message(call.message.chat.id, call.message.message_id)


# ===== ĞĞ‘Ğ©Ğ•ĞĞ˜Ğ• Ğ¡ Ğ˜Ğ˜ =====
def chat_thread(message):
    model = user_models.get(message.from_user.id, Config.DEFAULT_MODEL)
    bot.send_chat_action(message.chat.id, "typing")

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": message.text}],
            web_search=False
        )
        text = response.choices[0].message.content

        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
        update_stats(message.from_user.id, 'messages')

        max_length = Config.MAX_MESSAGE_LENGTH
        if len(text) > max_length:
            for i in range(0, len(text), max_length):
                bot.send_message(message.chat.id, text[i:i + max_length])
        else:
            bot.send_message(message.chat.id, text)

    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°: {e}")
        bot.send_message(
            message.chat.id,
            f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ Ğ¸Ğ»Ğ¸ ÑĞ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ‡ĞµÑ€ĞµĞ· /model"
        )


@bot.message_handler(func=lambda message: not message.text.startswith("/"), content_types=['text'])
def handle_text(message):
    threading.Thread(target=chat_thread, args=(message,), daemon=True).start()


# ===== Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ¯ =====
@bot.message_handler(commands=['help'])
def show_help(message):
    current_model = user_models.get(message.from_user.id, Config.DEFAULT_MODEL)
    current_image_model = user_image_models.get(message.from_user.id, Config.DEFAULT_IMAGE_MODEL)
    current_image_model_name = Config.IMAGE_MODEL_SETTINGS.get(current_image_model, {}).get('name', current_image_model)
    current_size = user_image_settings.get(message.from_user.id, {}).get('size', '1024x1024')

    help_text = f"""
ğŸ“– *Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ¯ ĞŸĞ Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ®*

ğŸ¤– ĞœĞ½Ğ¾Ğ³Ğ¾Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ˜Ğ˜-Ğ±Ğ¾Ñ‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—¨ï¸ *Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ*
/model - Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ

*Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:*
â€¢ GPT-4.1 - ÑĞ°Ğ¼Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ°Ñ
â€¢ GPT-4o - Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¸ ÑƒĞ¼Ğ½Ğ°Ñ
â€¢ GPT-4 - ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ°Ñ
â€¢ GPT-4o-mini - Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
â€¢ DeepSeek V3 - Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ°

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¨ *Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™*
/image_model - Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
/image_settings - Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€
/image <Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ> - ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ
/image_raw <Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ> - Ğ±ĞµĞ· ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹

*ĞœĞ¾Ğ´ĞµĞ»Ğ¸:*
â€¢ Flux (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)
â€¢ DALL-E 3
â€¢ Stable Diffusion XL
â€¢ Playground v2.5
â€¢ Midjourney

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” *ĞĞĞĞ›Ğ˜Ğ— Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™*
/analyze - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„Ğ¾Ñ‚Ğ¾

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š *Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ*
/stats - Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš™ï¸ *Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğ• ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜*
âœ… Ğ¢ĞµĞºÑÑ‚: `{current_model}`
ğŸ¨ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ: `{current_image_model_name}`
ğŸ“ Ğ Ğ°Ğ·Ğ¼ĞµÑ€: `{current_size}`

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¼Ğ½Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ!
"""
    bot.send_message(message.chat.id, help_text, parse_mode="Markdown")


# ===== GRACEFUL SHUTDOWN =====
def signal_handler(sig, frame):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ"""
    logging.info("ğŸ›‘ ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸")
    logging.info("ğŸ‘‹ Ğ‘Ğ¾Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ...")
    bot.stop_polling()
    sys.exit(0)


# ===== Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ‘ĞĞ¢Ğ =====
if __name__ == "__main__":
    # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ² ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    logging.info("=" * 50)
    logging.info("ğŸ¤– Ğ‘Ğ¾Ñ‚ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ!")
    logging.info("ğŸ“‹ ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹")
    logging.info("âœ… Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ°")
    logging.info("=" * 50)

    try:
        bot.polling(none_stop=True, interval=0, timeout=20)
    except KeyboardInterrupt:
        logging.info("Ğ‘Ğ¾Ñ‚ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")
    except Exception as e:
        logging.error(f"ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")

